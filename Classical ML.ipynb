{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c946208",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report as creport\n",
    "\n",
    "\n",
    "from multiprocessing import Pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76003c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfe816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv('dev_data.csv')\n",
    "dev_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62872932",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train data shape:{} \\nDev data shape: {}\".format(train_data.shape,dev_data.shape))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76e96a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64d5dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b64794",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Hate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1760f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot\n",
    "labels = 'NOT_HS', 'HS'\n",
    "sizes = [train_data['Hate'].value_counts()[0], train_data['Hate'].value_counts()[1]]\n",
    "colors = ['lightskyblue', 'yellow']\n",
    "explode = (0,0.2)  # explode 1st slice\n",
    "\n",
    "# Plot\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.title(\"Train Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5fae33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data['Hate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae676231",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data to plot\n",
    "labels = 'NOT_HS', 'HS'\n",
    "sizes = [dev_data['Hate'].value_counts()[0], dev_data['Hate'].value_counts()[1]]\n",
    "colors = ['lightskyblue', 'yellow']\n",
    "explode = (0,0.2)  # explode 1st slice\n",
    "\n",
    "# Plot\n",
    "plt.pie(sizes, explode=explode, labels=labels, colors=colors,\n",
    "autopct='%1.1f%%', shadow=True, startangle=140)\n",
    "\n",
    "plt.axis('equal')\n",
    "plt.title(\"Dev Data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c544d897",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3768a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(df):\n",
    "    df = remove_diacritics(df)\n",
    "    df = normalize_arabic(df)\n",
    "    df = remove_punctuations(df)\n",
    "    df = remove_repeating_char(df)\n",
    "    df= remove_english_word_and_numbers(df)\n",
    "    df=clean_space(df)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8e7f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "arabic_punctuations = '''`÷« »×؛<>٩٨'٧٦٥٤٣٢١٠_()↗*•&^%][ـ،/:\"؟.,'{}⋮≈~¦+|٪!”…“–ـ/[]%=#*+\\\\•~@£·_{}©^®`→°€™›♥←×§″′Â█à…“★”–●â►−¢¬░¶↑±▾\t═¦║―¥▓—‹─▒：⊕▼▪†■’▀¨▄♫☆é¯♦¤▲è¸Ã⋅‘∞∙）↓、│（»，♪╩╚³・╦╣╔╗▬❤ïØ¹≤‡₹´'''\n",
    "english_punctuations = string.punctuation\n",
    "punctuations_list = arabic_punctuations + english_punctuations\n",
    "\n",
    "arabic_diacritics = re.compile(\"\"\"\n",
    "                             ّ    | # Tashdid\n",
    "                             َ    | # Fatha\n",
    "                             ً    | # Tanwin Fath\n",
    "                             ُ    | # Damma\n",
    "                             ٌ    | # Tanwin Damm\n",
    "                             ِ    | # Kasra\n",
    "                             ٍ    | # Tanwin Kasr\n",
    "                             ْ    | # Sukun\n",
    "                             ـ     # Tatwil/Kashida\n",
    "                         \"\"\", re.VERBOSE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffb6541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_diacritics(df):\n",
    "    df['Tweet'] = df['Tweet'].apply(lambda x: _remove_diacritics(x))\n",
    "    return df\n",
    "def _remove_diacritics(x):\n",
    "    x = str(x)\n",
    "    x = re.sub(arabic_diacritics, '', x)\n",
    "    return x\n",
    "\n",
    "def normalize_arabic(df):\n",
    "    df['Tweet'] = df['Tweet'].apply(lambda x: _normalize_arabic(x))\n",
    "    return df\n",
    "def _normalize_arabic(x):\n",
    "    x = str(x)\n",
    "    # added space around puncts after replace\n",
    "    x = re.sub(\"[إأآا]\", \"ا\", x)\n",
    "    x = re.sub(\"ى\", \"ي\", x)\n",
    "    x = re.sub(\"ؤ\", \"ء\", x)\n",
    "    x = re.sub(\"ئ\", \"ء\", x)\n",
    "    x = re.sub(\"ة\", \"ه\", x)\n",
    "    x = re.sub(\"گ\", \"ك\", x)\n",
    "    return x\n",
    "\n",
    "def remove_punctuations(df):\n",
    "    df['Tweet'] = df['Tweet'].apply(lambda x: _remove_punctuations(x))\n",
    "    return df\n",
    "def _remove_punctuations(x):\n",
    "    x = str(x)\n",
    "    #translator = str.maketrans(' ', ' ', punctuations_list)\n",
    "    translator = str.maketrans(punctuations_list, ' '*len(punctuations_list))\n",
    "    return x.translate(translator)\n",
    "\n",
    "def remove_repeating_char(df):\n",
    "    df['Tweet'] = df['Tweet'].apply(lambda x: _remove_repeating_char(x))\n",
    "    return df\n",
    "def _remove_repeating_char(x):\n",
    "    x = str(x)\n",
    "    return re.sub(r'(.)\\1+', r'\\1', x)\n",
    "\n",
    "def remove_english_word_and_numbers(df):\n",
    "    df['Tweet'] = df['Tweet'].apply(lambda x: _remove_english_word_and_numbers(x))\n",
    "    return df\n",
    "def _remove_english_word_and_numbers(x):\n",
    "    x = str(x)\n",
    "    return re.sub(r'[a-zA-Z0-9]+', '', x)\n",
    "\n",
    "def clean_space(df):\n",
    "    compiled_re = re.compile(r\"\\s+\")\n",
    "    df['Tweet'] = df[\"Tweet\"].apply(lambda x: _clean_space(x, compiled_re))\n",
    "    return df\n",
    "def _clean_space(x, compiled_re):\n",
    "    return compiled_re.sub(\" \", x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf31999",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cores = 2\n",
    "def df_parallelize_run(df, func, num_cores=2):\n",
    "    df_split = np.array_split(df, num_cores)\n",
    "    pool = Pool(num_cores)\n",
    "    df = pd.concat(pool.map(func, df_split))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b556cbdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_cleaned = df_parallelize_run(train_data, clean)\n",
    "#train_data_cleaned.to_csv(\"train_data_cleaned.csv\", index=False)    #save the train_data_cleaned dataframe to csv\n",
    "dev_data_cleaned = df_parallelize_run(dev_data, clean)\n",
    "#dev_data_cleaned.to_csv(\"dev_data_cleaned.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e960da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a92588",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('/content/drive/My Drive/OSACT4/train_data_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4cd2f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dataset.iloc[:,0]\n",
    "y=dataset.iloc[:,2]\n",
    "X=x.to_dict()\n",
    "\n",
    "X=[]\n",
    "for d in range(len(x)):\n",
    "    b=x[d]\n",
    "    X.append(b) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee0f320",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect=CountVectorizer()\n",
    "X_train_counts=count_vect.fit_transform(X)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf= X_train_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8772e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9af5001",
   "metadata": {},
   "source": [
    "## SVM Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a7acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "clf= SVC(random_state = 0)\n",
    "clf.fit(X_train_tfidf, y)\n",
    "clf.score(X_train_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19691ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data = pd.read_csv('/content/drive/My Drive/OSACT4/dev_data_cleaned.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfbe1dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev=dev_data.iloc[:,0]\n",
    "y_dev=dev_data.iloc[:,2]\n",
    "#X=x_dev.to_dict()\n",
    "\n",
    "X=[]\n",
    "for d in range(len(x)):\n",
    "    b=x[d].lower()\n",
    "    X.append(b)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72661281",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_tfidf=count_vect.transform(x_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cc7707",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(X_dev_tfidf)\n",
    "print(creport(y_dev, y_pred,target_names=['HS', 'NOT_HS'],digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c6beea",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54bd82c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection, naive_bayes, svm, ensemble, tree\n",
    "from xgboost import XGBClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e259bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF= ensemble.RandomForestClassifier()\n",
    "RF.fit(X_train_tfidf, y)\n",
    "RF.score(X_train_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c972fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev=dev_data.iloc[:,0]\n",
    "y_dev=dev_data.iloc[:,2]\n",
    "X=x_dev.to_dict()\n",
    "\n",
    "X=[]\n",
    "for d in range(len(x)):\n",
    "    b=x[d].lower()\n",
    "    X.append(b)\n",
    "\n",
    "X_dev_tfidff=count_vect.transform(x_dev)\n",
    "y_pred=RF.predict(X_dev_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af53abe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(creport(y_dev, y_pred,target_names=['HS', 'NOT_HS'] ,digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7bd9291",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a110d91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DTC= tree.DecisionTreeClassifier()\n",
    "DTC.fit(X_train_tfidf, y)\n",
    "DTC.score(X_train_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "833499f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev=dev_data.iloc[:,0]\n",
    "y_dev=dev_data.iloc[:,2]\n",
    "X=x_dev.to_dict()\n",
    "\n",
    "X=[]\n",
    "for d in range(len(x)):\n",
    "    b=x[d].lower()\n",
    "    X.append(b)\n",
    "\n",
    "X_dev_tfidf=count_vect.transform(x_dev)\n",
    "y_pred=DTC.predict(X_dev_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc93564",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(creport(y_dev, y_pred,target_names=['HS', 'NOT_HS'],digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43734914",
   "metadata": {},
   "source": [
    "## Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac21bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "GBC= ensemble.GradientBoostingClassifier()\n",
    "GBC.fit(X_train_tfidf, y)\n",
    "GBC.score(X_train_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7f921",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev=dev_data.iloc[:,0]\n",
    "y_dev=dev_data.iloc[:,2]\n",
    "X=x_dev.to_dict()\n",
    "\n",
    "X=[]\n",
    "for d in range(len(x)):\n",
    "    b=x[d].lower()\n",
    "    X.append(b)\n",
    "\n",
    "X_dev_tfidf=count_vect.transform(x_dev)\n",
    "y_pred=GBC.predict(X_dev_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac895d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(creport(y_dev, y_pred,target_names=['HS', 'NOT_HS'],digits=4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a444fb2b",
   "metadata": {},
   "source": [
    "## Logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583f463b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import linear_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c919b7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "LR= linear_model.LogisticRegression()\n",
    "LR.fit(X_train_tfidf, y)\n",
    "LR.score(X_train_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03a0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_dev=dev_data.iloc[:,0]\n",
    "y_dev=dev_data.iloc[:,2]\n",
    "X=x_dev.to_dict()\n",
    "\n",
    "X=[]\n",
    "for d in range(len(x)):\n",
    "    b=x[d].lower()\n",
    "    X.append(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9563d0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev_tfidf=count_vect.transform(x_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=LR.predict(X_dev_tfidf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b1eb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(creport(y_dev, y_pred,target_names=['HS', 'NOT_HS'],digits=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
